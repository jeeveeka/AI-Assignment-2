{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.core import Activation, Flatten, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import random\n",
    "from keras import backend as K\n",
    "smooth = 1\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from keras.engine.topology import Input\n",
    "from keras.layers import concatenate,Conv2DTranspose\n",
    "if not os.path.exists('pickled'):\n",
    "    os.makedirs('pickled')\n",
    "print(\"Start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "if not os.path.exists('pickled/seg_data.pkl'):\n",
    "    directory = os.fsencode(\"melanoma\")\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file) \n",
    "        \n",
    "        path = str('melanoma\\\\' + filename)\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        \n",
    "        path = str('gt\\\\' + filename.split('.')[0] + '_segmentation.png')\n",
    "        \n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        labels.append(image)\n",
    "\n",
    "    directory = os.fsencode(\"others\")\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        path = str('others\\\\' + filename)\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        \n",
    "        path = str('gt\\\\' + filename.split('.')[0] + '_segmentation.png')\n",
    "        \n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        labels.append(image)\n",
    "        \n",
    "    d = {}\n",
    "    d['data'] = data\n",
    "    d['labels'] = labels\n",
    "    pickle.dump(d, open('pickled/seg_data.pkl', 'wb'))\n",
    "else:\n",
    "    d = pickle.load(open( 'pickled/seg_data.pkl', 'rb'))\n",
    "    data = d['data']\n",
    "    labels = d['labels']\n",
    "                \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels, dtype=\"float\") / 255.0\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data,labels, test_size=0.20, random_state=42)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 train samples\n",
      "400 test samples\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 1162s 726ms/step - loss: -0.4317 - dice_coef: 0.4317 - val_loss: -0.4929 - val_dice_coef: 0.4929\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 1186s 741ms/step - loss: -0.5226 - dice_coef: 0.5226 - val_loss: -0.5446 - val_dice_coef: 0.5446\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 1205s 753ms/step - loss: -0.5611 - dice_coef: 0.5611 - val_loss: -0.5825 - val_dice_coef: 0.5825\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 1151s 719ms/step - loss: -0.5860 - dice_coef: 0.5860 - val_loss: -0.6112 - val_dice_coef: 0.6112\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 1269s 793ms/step - loss: -0.6001 - dice_coef: 0.6001 - val_loss: -0.6161 - val_dice_coef: 0.6161\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 1104s 690ms/step - loss: -0.6125 - dice_coef: 0.6125 - val_loss: -0.6331 - val_dice_coef: 0.6331\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 1210s 756ms/step - loss: -0.6227 - dice_coef: 0.6227 - val_loss: -0.6380 - val_dice_coef: 0.6380\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 1234s 772ms/step - loss: -0.6290 - dice_coef: 0.6290 - val_loss: -0.6337 - val_dice_coef: 0.6337\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 1263s 790ms/step - loss: -0.6369 - dice_coef: 0.6369 - val_loss: -0.6389 - val_dice_coef: 0.6389\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 1312s 820ms/step - loss: -0.6417 - dice_coef: 0.6417 - val_loss: -0.6379 - val_dice_coef: 0.6379\n",
      "Sørensen–Dice_coefficient score : 0.6379313349723816\n"
     ]
    }
   ],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "img_input = Input((img_rows, img_cols, 3))\n",
    "\n",
    "x = img_input\n",
    "x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = UpSampling2D(size=(2, 2))(x)\n",
    "x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = UpSampling2D(size=(2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = UpSampling2D(size=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Conv2D(3, (1, 1), padding=\"valid\")(x)\n",
    "x = Activation(\"sigmoid\")(x)\n",
    "model = Model(img_input, x)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Sørensen–Dice_coefficient score :', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
